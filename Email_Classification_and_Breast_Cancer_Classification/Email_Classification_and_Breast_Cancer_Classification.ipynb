{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Detection\n",
    "\n",
    "In this problem, we will be constructing a crude spam detector. When we receive an e-mail, it can be divided into one of two types: ham (useful mail, label $-1$) and spam (junk mail, label $+1$).  \n",
    "\n",
    "We will be designing a spam detector by applying some of the classification techniques such as \n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Support Vector Machines\n",
    "\n",
    "to a batch of emails used to train and test [SpamAssassin](http://spamassassin.apache.org/), a leading anti-spam software package. \n",
    "\n",
    "Let the *vocabulary* of a dataset be a list of all terms occuring in a data set. So, for example, a vocabulary could be [\"cat\",\"dog\",\"chupacabra\", \"aerospace\", ...]. \n",
    "\n",
    "Our features will be based only the frequencies of terms in our vocabulary occuring in the e-mails (such an approach is called a *bag of words* approach, since we ignore the positions of the terms in the emails). The $j$-th feature is the number of times term $j$ in the vocabulary occurs in the email.\n",
    "\n",
    "We will use the following classifiers in this problem:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.linear_model.LogisticRegression (Logistic Regression)\n",
    "- sklearn.neighbors.KNeighborsClassifier (1-Nearest Neighbor Classifier)\n",
    "\n",
    "In the context of the Bernoulli Model for Naive Bayes, scikit-learn will binarize the features by interpretting the $j$-th feature to be $1$ if the $j$-th term in the vocabulary occurs in the email and $0$ otherwise. This is a categorical Naive Bayes model, with binary features. The multinomial model operates directly on the frequencies of terms in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample Ham email is:\n",
    "\n",
    "    From nic@starflung.com  Mon Jun 24 17:06:54 2002\n",
    "    Return-Path: 7910726.0.27May2002215326@mp.opensrs.net\n",
    "    Delivery-Date: Tue May 28 02:53:28 2002\n",
    "    Received: from mp.opensrs.net (mp.opensrs.net [216.40.33.45]) by\n",
    "        dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g4S1rSe14718 for\n",
    "        <zzz@spamassassin.taint.org>; Tue, 28 May 2002 02:53:28 +0100\n",
    "    Received: (from popensrs@localhost) by mp.opensrs.net (8.9.3/8.9.3) id\n",
    "        VAA04361; Mon, 27 May 2002 21:53:26 -0400\n",
    "    Message-Id: <7910726.0.27May2002215326@mp.opensrs.net>\n",
    "    Date: Mon, 27 May 2002 21:53:26 -0500 (EST)\n",
    "    From: \"Starflung NIC\" <nic@starflung.com>\n",
    "    To: <zzz@spamassassin.taint.org>\n",
    "    Subject: Automated 30 day renewal reminder 2002-05-27\n",
    "    X-Keywords: \n",
    "\n",
    "    The following domains that are registered as belonging\n",
    "    to you are due to expire within the next 60 days. If\n",
    "    you would like to renew them, please contact\n",
    "    nic@starflung.com; otherwise they will be deactivated\n",
    "    and may be registered by another.\n",
    "\n",
    "\n",
    "    Domain Name, Expiry Date\n",
    "    nutmegclothing.com, 2002-06-26\n",
    "    \n",
    "    \n",
    "A sample Spam email is: \n",
    "\n",
    "    From jjj@mymail.dk  Fri Aug 23 11:03:31 2002\n",
    "    Return-Path: <jjj@mymail.dk>\n",
    "    Delivered-To: zzzz@localhost.example.com\n",
    "    Received: from localhost (localhost [127.0.0.1])\n",
    "        by phobos.labs.example.com (Postfix) with ESMTP id 478B54415C\n",
    "        for <zzzz@localhost>; Fri, 23 Aug 2002 06:02:57 -0400 (EDT)\n",
    "    Received: from mail.webnote.net [193.120.211.219]\n",
    "        by localhost with POP3 (fetchmail-5.9.0)\n",
    "        for zzzz@localhost (single-drop); Fri, 23 Aug 2002 11:02:57 +0100 (IST)\n",
    "    Received: from smtp.easydns.com (smtp.easydns.com [205.210.42.30])\n",
    "        by webnote.net (8.9.3/8.9.3) with ESMTP id IAA08912;\n",
    "        Fri, 23 Aug 2002 08:13:36 +0100\n",
    "    From: jjj@mymail.dk\n",
    "    Received: from mymail.dk (unknown [61.97.34.233])\n",
    "        by smtp.easydns.com (Postfix) with SMTP\n",
    "        id 7484A2F85C; Fri, 23 Aug 2002 03:13:31 -0400 (EDT)\n",
    "    Reply-To: <jjj@mymail.dk>\n",
    "    Message-ID: <008c61d64eed$6184e5d5$4bc22de3@udnugg>\n",
    "    To: bbr_hooten@yahoo.com\n",
    "    Subject: HELP WANTED.  WORK FROM HOME REPS.\n",
    "    MiME-Version: 1.0\n",
    "    Content-Type: text/plain;\n",
    "        charset=\"iso-8859-1\"\n",
    "    X-Priority: 3 (Normal)\n",
    "    X-MSMail-Priority: Normal\n",
    "    X-Mailer: Microsoft Outlook, Build 10.0.2616\n",
    "    Importance: Normal\n",
    "    Date: Fri, 23 Aug 2002 03:13:31 -0400 (EDT)\n",
    "    Content-Transfer-Encoding: 8bit\n",
    "\n",
    "    Help wanted.  We are a 14 year old fortune 500 company, that is\n",
    "    growing at a tremendous rate.  We are looking for individuals who\n",
    "    want to work from home.\n",
    "\n",
    "    This is an opportunity to make an excellent income.  No experience\n",
    "    is required.  We will train you.\n",
    "\n",
    "    So if you are looking to be employed from home with a career that has\n",
    "    vast opportunities, then go:\n",
    "\n",
    "    http://www.basetel.com/wealthnow\n",
    "\n",
    "    We are looking for energetic and self motivated people.  If that is you\n",
    "    than click on the link and fill out the form, and one of our\n",
    "    employement specialist will contact you.\n",
    "\n",
    "    To be removed from our link simple go to:\n",
    "\n",
    "    http://www.basetel.com/remove.html\n",
    "\n",
    "\n",
    "    1349lmrd5-948HyhJ3622xXiM0-290VZdq6044fFvN0-799hUsU07l50\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the data. Our dataset has a bit over 9000 emails, with about 25% of them being spam. We will use 50% of them as a training set, 25% of them as a validation set and 25% of them as a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of emails\n",
    "spamfiles=glob.glob('./Data/Spam/*')\n",
    "hamfiles=glob.glob('./Data/Ham/*')\n",
    "type(hamfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will split the files into the training, validation and test sets.\n",
    "\n",
    "np.random.seed(seed=222017) # seed the RNG for repeatability\n",
    "\n",
    "fnames=np.asarray(spamfiles+hamfiles)\n",
    "nfiles=fnames.size\n",
    "labels=np.ones(nfiles)\n",
    "labels[len(spamfiles):]=-1\n",
    "\n",
    "# Randomly permute the files we have\n",
    "idx=np.random.permutation(nfiles)\n",
    "fnames=fnames[idx]\n",
    "labels=labels[idx]\n",
    "\n",
    "#Split the file names into which set they belong to\n",
    "tname=fnames[:int(nfiles/2)]\n",
    "trainlabels=labels[:int(nfiles/2)]\n",
    "vname=fnames[int(nfiles/2):int(nfiles*3/4)]\n",
    "vallabels=labels[int(nfiles/2):int(nfiles*3/4)]\n",
    "tename=fnames[int(3/4*nfiles):]\n",
    "testlabels=labels[int(3/4*nfiles):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Get our Bag of Words Features from the data\n",
    "bow = CountVectorizer(input='filename',encoding='iso-8859-1',binary=False)\n",
    "traindata=bow.fit_transform(tname)\n",
    "valdata=bow.transform(vname)\n",
    "testdata=bow.transform(tename)\n",
    "type(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $100$ most and least common terms in the vocabulary are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 most common terms:  as,have,not,slashnull,dogma,request,thu,ist,mail,cnet,are,lists,wed,jmason,or,exmh,freshrpms,html,mailman,mon,00,12,date,message,ie,text,users,bgcolor,postfix,09,type,align,rpm,linux,arial,22,version,be,your,taint,mailto,admin,content,sourceforge,table,on,20,color,border,jm,aug,gif,example,this,127,href,img,face,src,10,subject,nbsp,that,it,sep,0100,height,spamassassin,esmtp,is,xent,fork,size,you,in,www,tr,br,list,11,width,received,of,and,localhost,id,org,by,with,net,for,td,http,font,3d,2002,from,the,to,com \n",
      "\n",
      "100 least common terms:  bjkwasvqaww7aidwbawacabaazqbxthxxtuhfzraa9cab4dabujgccrqcnxgasdgbe4abaudbviw,di09bpkfnyor9plfsy2k1x0rrjfrd3lyxe1pf9,painfree,di4ogzxbde4xbwtydpn3gowojdjjakl3teark4n2ezk4tu5wziny,di79lua5r2hzsc1wycoous63kg026atmbci2,di9f,diagn,paictkoa9mibhkigds8p6vm,pahdtw85r7jtuzknjeqccngoqyuk5cqub,pah,diagrammatic,pagetype,pagers,pagereq,dial12,painfull,dialcom,pageid,page1_11,page1_10,page1_09,page1_08,page1_07,dialoguez,dialpool,page1_06,page1_05,page1_04,dialup138,dialup459,dialups,dialer,page1_03,dhéanamh,dhvyzxmgmjawmq0kqm94idq0nsbtdgf0aw9uig1haw4grwrtb250b24uqwxi,dhkjnveioq30w9zj61u2srtfypy2t0h056b6dzjo,pajcjeepfksl8gthzea4ukhkr,dhl2jxhjc,dhmgb2ygbw9uzxkgaw4gdghligz1dhvyzs4giexvb2tpbmcgzm9yd2fyzcb0,dhmgc2hvd24gb24gdghligxpc3qgymvsb3cgpt09pt0ncianckzvciblywno,dhmsig5vihb1bxbzlcbubybzdxjnzxj5ice8l2rpdj48cd5jzib5b3ugd2fu,dhmvaw5kzxguahrtpia8zm9udcbjb2xvcj15zwxsb3cgc2l6zt0rmt5uzwvu,dhmvrm9ybwf0sw1hz2uudhh0dqotlt4ncjxhighyzwy9ikhuvfa6ly9xv1cu,dhmvrm9ybwf0vgv4dc50ehqnci0tpg0kdqo8zm9udcbmywnlpsjbcmlhbcxi,dhnzu,dhonncha,dhox9wsaholliacfohsqp,dhpjqvzkxf5gxliiimjkhje6yrp,pajae,dhx8njphc6s0tqwhqhfcpng0ctgj11ix0erreo73trdwzttzi4np4zdcx8mgpq6txtrvy,dhrlcnm7ig5vdcbvbmx5igl0igfmzmvjdhmgbwfuesbtzw4ncybwzxjmb3jt,dhrvbt48l1repjwvvfi,dhrwoi8vaw1hz2vzlnrhbgtjaxr5lmnvbs9pbwcvag9tzxbhz2vzl2nvdw50,dhrwoi8vd3d3lmludmvzdg1lbnq0ds5jb20vu3bly2lhbfjlcg9ydc8ipkns,dhrwoi8vd3d3lndlymrldmvsb3blci5jb20vyw5pbwf0aw9ucy9ibmlmawxlcy9ibhvsdgjh,paisanos,pairings,pairing,dhsfrvhrkkasq,paired,dhtl7vk04kagqtgu,dhumjgyndmam2qzzdq0njg1advonda2odaknww3edfgoew4udkkoza5,painstaking,dhvkzw50cywgcmvhzgluzyblbnrodxnpyxn0cywgb3igdghlihzpc2lvbibpbxbhaxjlzdwv,dhvyzs4ncianclnpbmnlcmvseswncianckrvbwfpbibbzg1pbmlzdhjhdg9y,dhrszsb0agf0ihrozxjldqp3yxmganvzdcbubyb3yxkgdghhdcbjihdvdwxk,diametre,page1_022,diamondmax,didius,didxgcjdrjg,paa32576,die4rsibkl,paa32564,paa32554,diehard,diem_t,dierks,paa32552,paa32428,paa32424,diesem,paa32422,paarllel,paa32161,paa32083,paa32058,dieties,paa31959,paa31911,paa31883,paa31869,paa31847,paa31843,paa30448,paa30415,differen,paa30102,paa30077,diesjährige\n"
     ]
    }
   ],
   "source": [
    "counts=np.reshape(np.asarray(np.argsort(traindata.sum(axis=0))),-1)\n",
    "vocab=np.reshape(np.asarray(bow.get_feature_names()),-1)\n",
    "print (\"100 most common terms: \" , ','.join(str(s) for s in vocab[counts[-100:]]), \"\\n\")\n",
    "print (\"100 least common terms: \" , ','.join(str(s) for s in vocab[counts[:100]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have our training data in `traindata` (with labels in `trainlabels`), validation data in `valdata` (with labels in `vallabels`) and test data in `testdata` (with labels in `testlabels`). The data is stored as a sparse scipy matrix (`scipy.sparse.csr.csr_matrix`), since we have a decent number of features (~ 100k), most of which are zero (~ 0.2% are non-zero), this allows storing the data in a few megabytes. Directly storing it as a numpy array (as we did in lab 1) would take around 8 gigabytes. Working with sparse data can make many algorithms run faster and use less storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train each of the following classifiers :\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.linear_model.LogisticRegression (Logistic Regression)\n",
    "- sklearn.neighbors.KNeighborsClassifier (as a 1-Nearest Neighbor Classifier)\n",
    "on the training data in `traindata` with corresponding labels `trainlabels`.\n",
    "\n",
    "For each classifier, we report:\n",
    "- Time it took to fit the classifier (i.e. call the .fit method)  \n",
    "- Training Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.metrics import zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in  BernoulliNB Classifier 0.100 secs\n",
      "Error in BernoulliNB Classifier 5.285 %\n",
      "----------------------------------------------\n",
      "Time taken in  MultinomialNB Classifier 0.021 secs\n",
      "Error in MultinomialNB Classifier 1.861 %\n",
      "----------------------------------------------\n",
      "Time taken in  LinearSVC Classifier 5.709 secs\n",
      "Error in LinearSVC Classifier 0.000 %\n",
      "----------------------------------------------\n",
      "Time taken in  LogisticRegression Classifier 10.830 secs\n",
      "Error in LogisticRegression Classifier 0.000 %\n",
      "----------------------------------------------\n",
      "Time taken in  KNeighborsClassifier Classifier 0.005 secs\n",
      "Error in KNeighborsClassifier Classifier 0.000 %\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clfs=[BernoulliNB,MultinomialNB,LinearSVC,LogisticRegression,KNeighborsClassifier]\n",
    "trained_objects=dict()\n",
    "# clfs=[\"BernoulliNB\",\"MultinomialNB\"]\n",
    "for x in clfs:\n",
    "    \n",
    "    if (x.__name__ == \"KNeighborsClassifier\"): #setting the KNeighborsClassifier k=1\n",
    "        obj=x(n_neighbors=1)\n",
    "    elif(x.__name__ == \"LinearSVC\"):   # setting dual = false or else the calculation fails to converge\n",
    "        obj=x(dual=False)\n",
    "    elif(x.__name__ == \"LogisticRegression\"): # increasing max_iter or the calculation fails to converge \n",
    "        obj=x(max_iter=7600,solver='lbfgs')\n",
    "    else:\n",
    "        obj=x()\n",
    "        \n",
    "    trained_objects[x.__name__] = obj   # associating variable names with classifier object\n",
    "    srt_tm = time.time()  #starting the time\n",
    "    obj.fit(traindata, trainlabels) #training the classfiers\n",
    "    t_taken = time.time() - srt_tm #stopping the time\n",
    "    print(\"Time taken in \",x.__name__,\"Classifier %2.3f\" %t_taken,\"secs\")\n",
    "    print(\"Error in\",x.__name__,\"Classifier %2.3f\" %(zero_one_loss(trainlabels,obj.predict(traindata))*100),\"%\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Linear SVM and Logistic regression have zero training errors this is because data is linearly separable, and the classifiers just have to predict whether the email is spam or not (multinomial distribution with the 0-1 loss function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run each of the classifiers on the validation data:\n",
    "- sklearn.naive_bayes.BernoulliNB (Naive Bayes Classifier with Bernoulli Model)\n",
    "- sklearn.naive_bayes.MultinomialNB (Naive Bayes Classifier with Multinomial Model)\n",
    "- sklearn.svm.LinearSVC (Linear Support Vector Machine)\n",
    "- sklearn.linear_model.LogisticRegression (Logistic Regression)\n",
    "- sklearn.neighbors.KNeighborsClassifier (as a 1-Nearest Neighbor Classifier)\n",
    "on the training data in `traindata` with corresponding labels `trainlabels`.\n",
    "\n",
    "For each classifier, we do the following:\n",
    "- Store the labels it predicted as \\_\\_vallabels, where \\_\\_ is NB,MB,SVM,LR,NN respectively.\n",
    "- Time it took to run the classifier on the data\n",
    "- Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in BernoulliNB Classifier 9.799 %\n",
      "Time taken in  BernoulliNB Classifier 0.025 secs\n",
      "----------------------------------------------\n",
      "Error in MultinomialNB Classifier 3.594 %\n",
      "Time taken in  MultinomialNB Classifier 0.014 secs\n",
      "----------------------------------------------\n",
      "Error in LinearSVC Classifier 1.455 %\n",
      "Time taken in  LinearSVC Classifier 0.007 secs\n",
      "----------------------------------------------\n",
      "Error in LogisticRegression Classifier 1.369 %\n",
      "Time taken in  LogisticRegression Classifier 0.007 secs\n",
      "----------------------------------------------\n",
      "Error in KNeighborsClassifier Classifier 2.268 %\n",
      "Time taken in  KNeighborsClassifier Classifier 3.391 secs\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "prefix=[\"NB_vallabels\",\"MB_vallabels\",\"SVM_vallabels\",\"LR_vallabels\",\"NN_vallabels\"]\n",
    "mapped_names=dict()\n",
    "for x in trained_objects:\n",
    "    srt_tm = time.time() #starting the time\n",
    "    val_labels = trained_objects[x].predict(valdata)  # predicting the labels usign the classifires trained before\n",
    "    t_taken = time.time() - srt_tm #stoping the time\n",
    "    tracker = prefix[list(trained_objects.keys()).index(x)]\n",
    "    locals()[tracker] = val_labels #associating the labels of different classifiers according to the variable names in the question\n",
    "    mapped_names[tracker] = x\n",
    "    print(\"Error in\",x,\"Classifier %2.3f\" %(zero_one_loss(vallabels,val_labels)*100),\"%\")\n",
    "    print(\"Time taken in \",x,\"Classifier %2.3f\" %t_taken,\"secs\")\n",
    "    print(\"----------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a more nuanced look at the type of errors made on a data set. The following function calculates a confusion matrix and some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConfMatr(truelabels,estimatedlabels,classifiername):\n",
    "    # classifiername is a string, such as 'Naive Bayes (Bernoulli)'\n",
    "    cm=np.zeros((2,2))\n",
    "    cm[0,0]=np.sum(np.logical_and(truelabels==1,estimatedlabels==1)) # True Positives\n",
    "    cm[0,1]=np.sum(np.logical_and(truelabels==-1,estimatedlabels==1)) # False Positive\n",
    "    cm[1,0]=np.sum(np.logical_and(truelabels==1,estimatedlabels==-1)) # False Negative\n",
    "    cm[1,1]=np.sum(np.logical_and(truelabels==-1,estimatedlabels==-1)) # True Negatives\n",
    "    print (\"Classifier Name: %s\"% classifiername )\n",
    "    print (\"True Positives:\", cm[0,0], \"False Positive:\", cm[0,1])\n",
    "    print (\"False Negative:\", cm[1,0], \"True Negatives:\", cm[1,1])\n",
    "    print (\"True Positive Rate : \", cm[0,0]/np.sum(truelabels==1))\n",
    "    print (\"False Positive Rate: \", cm[0,1]/np.sum(truelabels==-1))\n",
    "    print (\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run ConfMatr using the validation labels and their estimates for all the classifiers we've used in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Name: BernoulliNB\n",
      "True Positives: 394.0 False Positive: 21.0\n",
      "False Negative: 208.0 True Negatives: 1714.0\n",
      "True Positive Rate :  0.654485049833887\n",
      "False Positive Rate:  0.012103746397694525\n",
      "---\n",
      "Classifier Name: MultinomialNB\n",
      "True Positives: 527.0 False Positive: 9.0\n",
      "False Negative: 75.0 True Negatives: 1726.0\n",
      "True Positive Rate :  0.8754152823920266\n",
      "False Positive Rate:  0.005187319884726225\n",
      "---\n",
      "Classifier Name: LinearSVC\n",
      "True Positives: 593.0 False Positive: 25.0\n",
      "False Negative: 9.0 True Negatives: 1710.0\n",
      "True Positive Rate :  0.9850498338870431\n",
      "False Positive Rate:  0.01440922190201729\n",
      "---\n",
      "Classifier Name: LogisticRegression\n",
      "True Positives: 591.0 False Positive: 21.0\n",
      "False Negative: 11.0 True Negatives: 1714.0\n",
      "True Positive Rate :  0.9817275747508306\n",
      "False Positive Rate:  0.012103746397694525\n",
      "---\n",
      "Classifier Name: KNeighborsClassifier\n",
      "True Positives: 577.0 False Positive: 28.0\n",
      "False Negative: 25.0 True Negatives: 1707.0\n",
      "True Positive Rate :  0.9584717607973422\n",
      "False Positive Rate:  0.016138328530259365\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for x in mapped_names:\n",
    "    ConfMatr(vallabels, locals()[x], mapped_names[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The True positive rate is the fraction of emails that were spam that the classifier also correctly classified them as spam. The false-positive rate is the fraction of emails that were not spam but the classifier classified them as spam. The true positive rate should be high (close to 1 meaning spam classified as spam) while the false positive rate should be low (close to 0 meaning we should not classify ham as spam) \n",
    "\n",
    "Based on the results of the classfiers on the validation set, we will choose Linear Support Vector Machine classifier as it has the highest true positive rates and one of the lowest false positive rates. We think this is an appropriate choice since it filters the most amount of spam emails. In a university setting the amount of spam must be really high so choosing the best classifier (based on true positive rate) is a good choice while making some tradeoff with the false positive rate. I will keep updating my training set as the users at the university mark emails as spam. This will help the classifier train on larger training set.\n",
    "______________________________________________________________________________________________\n",
    "\n",
    "We could add additional features to the SVM classifier based on the IP address of the sender, emails from a list of trusted email domains or if the email address are in the user's address book, email addressed to the recipient's name and not his or her email address. I will continuously update the training data if the user marks an email as spam or marks spam as ham. We will also check if the email has an attachment or not and the extension of the attachment(.pdf is safe while a .exe is not). Filtering everyone's email jointly may not be a good idea as it may slow down the process of classification however I will actively scan the number of recipients on the email, spam emails are generally sent to a lot of recipients.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run the classifier we selected in the previous part of the problem on the test data, and display test error and output of ConfMatr. we also comment on the true/false positive rate and error as compared to that on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in LinearSVC Classifier 1.069 %\n",
      "Classifier Name: LinearSVC\n",
      "True Positives: 614.0 False Positive: 19.0\n",
      "False Negative: 6.0 True Negatives: 1699.0\n",
      "True Positive Rate :  0.9903225806451613\n",
      "False Positive Rate:  0.011059371362048894\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_labels = trained_objects[\"LinearSVC\"].predict(testdata)\n",
    "print(\"Error in\",'LinearSVC',\"Classifier %2.3f\" %(zero_one_loss(testlabels,test_labels)*100),\"%\")\n",
    "ConfMatr(testlabels, test_labels, \"LinearSVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the TPR was higher and FRP was lower on the test data than on the validation data. The error on the test data was also lower (by around 0.5%) as compared to the validation data. We also observe a reduction in the number of false-negative (spam incorrectly classified as ham)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting Cancer with SVMs and Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the [Breast Cancer Wisconsin Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) from \n",
    "W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. \n",
    "\n",
    "The authors diagnosed people by characterizing 3 cell nuclei per person extracted from the breast (pictures [here](http://web.archive.org/web/19970225174429/http://www.cs.wisc.edu/~street/images/)), each with 10 features (for a 30-dimensional feature space):\n",
    "\n",
    "1. radius (mean of distances from center to points on the perimeter) \n",
    "\n",
    "2. texture (standard deviation of gray-scale values) \n",
    "\n",
    "3. perimeter \n",
    "\n",
    "4. area \n",
    "\n",
    "5. smoothness (local variation in radius lengths) \n",
    "\n",
    "6. compactness (perimeter^2 / area - 1.0) \n",
    "\n",
    "7. concavity (severity of concave portions of the contour) \n",
    "\n",
    "8. concave points (number of concave portions of the contour) \n",
    "\n",
    "9. symmetry \n",
    "\n",
    "10. fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "and classified the sample into one of two classes: Malignant ($+1$) or Benign ($-1$). We will be attempting to classify if a sample is Malignant or Benign using Support Vector Machines, as well as Logistic Regression. Since we don't have all that much data, we will use 10-fold cross-validation to tune our parameters for our SVMs and Logistic Regression. We use 90% of the data for training, and 10% for testing.\n",
    "\n",
    "We will be experimenting with SVMs using Gaussian RBF kernels through sklearn.svm.SVC, linear SVMs through sklearn.svm.LinearSVC, and sklearn.linear_model.LogisticRegression for Logistic Regression. \n",
    "\n",
    "Our model selection will be done with cross-validation via sklearn.model_selection's cross_val_score. This returns the accuracy for each fold, i.e. the fraction of samples classified correctly. Thus, the cross-validation error is simply 1-mean(cross_val_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data. We will use scikit-learn's train test split function to split the data. The data is also scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = genfromtxt('Data/wdbc.csv', delimiter=',')\n",
    "\n",
    "np.random.seed(seed=282017) # seed the RNG for repeatability\n",
    "idx=np.random.permutation(cancer.shape[0])\n",
    "cancer=cancer[idx]\n",
    "\n",
    "cancer_features=cancer[:,1:]\n",
    "cancer_labels=cancer[:,0]\n",
    "\n",
    "#The training data is in data_train with labels label_train. \n",
    "# The test data is in data_test with labels label_test.\n",
    "data_train, data_test, label_train, label_test = train_test_split(cancer_features,cancer_labels,test_size=0.1,random_state=292017)\n",
    "\n",
    "# Rescale the training data and scale the test data correspondingly\n",
    "scaler=MinMaxScaler(feature_range=(-1,1))\n",
    "data_train=scaler.fit_transform(data_train) #Note that the scaling is determined solely via the training data!\n",
    "data_test=scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soft margin linear SVM is tuned based on a parameter $C$, which controls how much points can be violating the margin. \n",
    "\n",
    "We use cross-validation to select a value of $C$ for a linear SVM (sklearn.svm.LinearSVC) by varying $C$ from $2^{-5},2^{-4},\\ldots,2^{15}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum error is  2.714932126696823\n",
      "Postion of the min. error in C vector 2\n",
      "Value of C= 0.125 = 2^-3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "nos=range(-5,16,1)\n",
    "C_data=[2**i for i in nos]\n",
    "errors_C=[]\n",
    "for x in C_data:\n",
    "    clf = LinearSVC(dual=False,C=x)\n",
    "    scores = cross_val_score(clf, data_train, label_train, cv=10)\n",
    "    errors_C.append((1-(scores.mean()))*100)\n",
    "# print(errors_C)\n",
    "min_pos=np.argmin(np.asarray(errors_C))\n",
    "print(\"Minimum error is \",errors_C[min_pos])\n",
    "print(\"Postion of the min. error in C vector\",min_pos)\n",
    "print(\"Value of C=\",C_data[min_pos],\"=\",\"2^-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The value of C=2^-3 should be choosen since it gives the minimum error cross-validation error which is about 2.71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now experiment with using kernels in an SVM, particularly the Gaussian RBF kernel (in sklearn.svm.SVC). The SVM has two parameters to tune in this case: $C$ (as before), and $\\gamma$, which is a parameter in the RBF. \n",
    "\n",
    "We use cross-validation to select parameters $(C,\\gamma)$ by searching varying $(C,\\gamma)$ over $C=2^{-5},2^{-4},\\ldots,2^{15}$ and $\\gamma=2^{-15},\\ldots,2^{3}$ [So, we will try about 400 parameter choices]. Out of these, we choose $(C,\\gamma)$ parameters that will give us min. cross-validation error.\n",
    "\n",
    "We are using a fairly coarse grid for this problem, but one could use a finer grid once the rough range of good parameters is known (rather than starting with a fine grid, which would waste a lot of time). <b></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_nos=range(-15,3,1)\n",
    "G_data=[2**i for i in g_nos]\n",
    "error_CG=np.zeros((len(C_data),len(g_nos)))\n",
    "for i in range(0,len(C_data)):\n",
    "    for j in range(0,len(G_data)):\n",
    "        clf2 = SVC(C=C_data[i],gamma=G_data[j])\n",
    "        scores = cross_val_score(clf2, data_train, label_train, cv=10)\n",
    "        error_CG[i,j]=(1-scores.mean())*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 12)\n",
      "The min error is 1.9457013574660564\n",
      "The value of C for min error is 8\n",
      "The value of Gamma for min is 0.125\n"
     ]
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmin(error_CG, axis=None), error_CG.shape)\n",
    "print(ind)\n",
    "print(\"The min error is\",error_CG[ind])\n",
    "print(\"The value of C for min error is\",C_data[ind[0]])\n",
    "print(\"The value of Gamma for min is\",G_data[ind[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We should choose C=8=2^3 and Gamma=0.125=2^-3 as parameters for our classfiers as these give the minimum error which is 1.945%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that Logistic Regression normally has a regularizer parameter to promote stability. Scikit-learn calls this parameter $C$. We use cross-validation to select a value of $C$ for logistic regression (sklearn.linear_model.LogisticRegression) by varying $C$ from $2^{-14},2^{-4},\\ldots,2^{14}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "nos_new=range(-14,14,1)\n",
    "C_new=[2**i for i in nos_new]\n",
    "lgr_error=[]\n",
    "for x in C_new:\n",
    "    lgr = LogisticRegression(max_iter=5000,solver='lbfgs',C=x)\n",
    "    scores = cross_val_score(lgr, data_train, label_train, cv=10)     \n",
    "    lgr_error.append((1-(scores.mean()))*100)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum error is 2.1342383107088914\n",
      "The C value for minimum error is 1\n"
     ]
    }
   ],
   "source": [
    "minerr=np.argmin(np.asarray(lgr_error))\n",
    "print(\"The minimum error is\",min(lgr_error))\n",
    "print(\"The C value for minimum error is\",C_new[minerr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The value of C that should be choose is C=1 = 2^0  which has 2.1342% cross validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Based on our observations on the cross-validation errors so far for the optimum C and Gamma values: <br>\n",
    "    Linear SVM - 2.71493%  <br>\n",
    "    SVM + Gaussian RBF- 1.9457% <br>\n",
    "    Logistic Regression-2.13423 % <br>\n",
    "I would choose the Logistic classifier since its cross-validation error is one of the lowest and computationally takes much less time compared to SVM + Gaussian RBF which needs to optimize two parameters first. The logistic regression classifier error is just ~0.2 percent higher than SVM + Gaussian RBF and has a much lower computational cost. Considering that the application is predicting malignancy we have the option of further testing (biopsy) if our predictions are inaccurate and so lower computational cost (which lowers the price of the test) is preferred."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
